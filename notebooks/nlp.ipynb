{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3b9b742c",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "# Uninstall potential conflicting packages\n",
                "!{sys.executable} -m pip uninstall -y scikit-learn sklearn\n",
                "# Reinstall tensorflow and scikit-learn\n",
                "!{sys.executable} -m pip install tensorflow scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2490a5cd",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from tensorflow.keras.preprocessing.text import Tokenizer\n",
                "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "\n",
                "print(\"Libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c81e39d1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Data\n",
                "file_path = r\"D:\\Projects\\tentier-streamlit\\data\\PRDECT-ID Dataset.csv\"\n",
                "df = pd.read_csv(file_path)\n",
                "print(df.head())\n",
                "print(df['Sentiment'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6df16fa2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preprocessing\n",
                "df = df[['Customer Review', 'Sentiment']].dropna()\n",
                "X = df['Customer Review'].astype(str)\n",
                "y = df['Sentiment']\n",
                "\n",
                "# Encode Labels\n",
                "le = LabelEncoder()\n",
                "y = le.fit_transform(y)\n",
                "print(\"Classes:\", le.classes_)\n",
                "\n",
                "# Tokenization\n",
                "max_words = 5000\n",
                "max_len = 100\n",
                "tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
                "tokenizer.fit_on_texts(X)\n",
                "X = tokenizer.texts_to_sequences(X)\n",
                "X = pad_sequences(X, maxlen=max_len)\n",
                "\n",
                "# Train/Test Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9c413ac1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build LSTM Model\n",
                "embedding_dim = 128\n",
                "num_classes = len(np.unique(y))\n",
                "\n",
                "model = Sequential()\n",
                "model.add(Embedding(max_words, embedding_dim, input_length=max_len))\n",
                "model.add(SpatialDropout1D(0.2))\n",
                "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
                "\n",
                "if num_classes == 2:\n",
                "    model.add(Dense(1, activation='sigmoid'))\n",
                "    loss = 'binary_crossentropy'\n",
                "else:\n",
                "    model.add(Dense(num_classes, activation='softmax'))\n",
                "    loss = 'sparse_categorical_crossentropy'\n",
                "\n",
                "model.compile(loss=loss, optimizer='adam', metrics=['accuracy'])\n",
                "print(model.summary())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4b4e8962",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Model\n",
                "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate Model\n",
                "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
                "print(f'Test Accuracy: {accuracy}')\n",
                "\n",
                "y_pred = model.predict(X_test)\n",
                "if num_classes == 2:\n",
                "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
                "else:\n",
                "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
                "\n",
                "print(classification_report(y_test, y_pred_classes, target_names=le.classes_))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot Training History\n",
                "plt.figure(figsize=(12, 4))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
                "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
                "plt.legend()\n",
                "plt.title('Accuracy')\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(history.history['loss'], label='Train Loss')\n",
                "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
                "plt.legend()\n",
                "plt.title('Loss')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export Model and Tokenizer\n",
                "import pickle\n",
                "import os\n",
                "\n",
                "models_dir = r'D:\\Projects\\tentier-streamlit\\models'\n",
                "if not os.path.exists(models_dir):\n",
                "    os.makedirs(models_dir)\n",
                "\n",
                "# Save Model\n",
                "model.save(os.path.join(models_dir, 'sentiment_model.h5'))\n",
                "print(f\"Model saved to {os.path.join(models_dir, 'sentiment_model.h5')}\")\n",
                "\n",
                "# Save Tokenizer\n",
                "with open(os.path.join(models_dir, 'tokenizer.pickle'), 'wb') as handle:\n",
                "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
                "print(f\"Tokenizer saved to {os.path.join(models_dir, 'tokenizer.pickle')}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}